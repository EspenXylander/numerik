{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmieraufgabe II  ( 6+6+12+6 = 30 Punkte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e0e1492b7973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe a:  Gradientenverfahren mit Armijo-Schrittweite (6 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie das Gradientenverfahren mit Armijo-Linesearch:\n",
    "\n",
    "Als Input sollen übergeben werden: \n",
    "\n",
    "* eine Funktion $f$ sowie eine weitere Funktion $gradf$, die den Gradienten von $f$ berechnet,  \n",
    "* ein Startwert $x_0$,\n",
    "* eine Toleranz $tol > 0$ sowie die maximale Anzahl $itmax$ an Gradientenschritten, \n",
    "* die zwei Parameter $\\beta$, $c$ für die Schrittweitenbestimmung nach Armijo sowie die maximale Anzahl $armijoitmax$ der dafür ausgeführten Iterationen.\n",
    "\n",
    "Output soll eine Iterierte $x_{k^*}$ sein, die $\\lVert \\nabla f(x_{k^*}) \\rVert < \\epsilon$ erfüllt. Zusätzlich sollen Listen mit den Funktionswerten $(f(x_k))_k$ (\"$fvals$\") bzw. den Iterierten $(x_k)_k$ (\"$xvals$\") ausgegeben werden. \n",
    "\n",
    "Im Falle des Versagens des Algorithmus bzw. von Teilen des Algorithmus sollen entsprechende Fehlermeldungen ausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent_armijo(f, gradf, x0, tol, c, beta, itmax, armijoitmax):\n",
    "    \n",
    "    ## to be filled in ## \n",
    "    \n",
    "    return x, xvals, fvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen Sie Ihre Implementierung an folgenden Beispielen (mit $x^*$ sind jeweils die bekannten Minima angegeben): \n",
    "\n",
    "* $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}, (x_1, x_2) \\mapsto 100(x_2 -x_1^2)^2 + (1-x_1)^2$, $x^* = (1,1)$.  \n",
    "* $g: \\mathbb{R}^{100} \\rightarrow \\mathbb{R}, x \\mapsto \\frac{1}{2} x^T A x - b^T x$, mit $b = Ax^*$, $x^* = (1,1,...,1)^T$. $A$ ist die $100 \\times 100$-Matrix mit $4$en auf der Hauptdiagonale, $-1$ auf den beiden Nebendiagonalen und sonst Nulleinträgen.  \n",
    "* $h: \\mathbb{R} \\rightarrow \\mathbb{R}$, $x \\mapsto exp(-1/x^2)$, $x^* = 0$.  \n",
    "\n",
    "Plotten Sie dazu sowohl die Verläufe von $f(x_k)-f(x^*)$ als auch von $\\lVert x_k - x^* \\rVert_2$ (analog für $g$,$h$) für den Startwerten $x_0 = 0$ ($f$ und $g$) bzw. $x_0 = 1$ (für $h$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe b: Gradientenverfahren mit konstanter Schrittweite (6 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie analog zu Teilaufgabe a) den Gradientenabstieg mit konstanter Schrittweite $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent_const(f, gradf, x0, tol, alpha, itmax):\n",
    "    \n",
    "    ## to be filled in ## \n",
    "    \n",
    "    return x, xvals, fvals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleichen Sie das Konvergenzverhalten des Gradientenverfahrens mit konstanter Schrittweite mit Ihren Ergebnissen aus \n",
    "Teilaufgabe a). Verwenden Sie dazu dieselben drei Funktionen $f$, $g$ und $h$, die gleichen Startwerte und testen Sie Schrittweiten $\\alpha \\in \\{ 0.5, 0.3, 0.1, 0.01, 0.005, 0.003, 0.002 \\}$. Interpretieren Sie Ihr Ergebnis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe c: Gradientenverfahren vs. CG-Verfahren  (12 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie für eine positiv definite Matrix $A$, eine rechte Seite $b$ und einen Startwert $x_0$ den Gradientenabstieg mit exakter Schrittweite für die Lösung der linearen Gleichung $Ax = b$. Neben $A$ und $b$ sollen als Input eine Toleranz $tol$ für die Norm des Gradienten sowie eine maximale Anzahl $itmax$ von Gradientenschritten vorgegeben werden. \n",
    "\n",
    "Implementieren Sie analog dazu das CG-Verfahren für $Ax = b$ und vergleichen Sie die Konvergenzgeschwindigkeit des Gradientenverfahrens mit der des CG-Verfahrens anhand von $A$, $b$ aus Teilaufgabe a): Erstellen Sie dazu eine Graphik, in der Sie die Konvergenzgeschwindikeit aller vier Verfahren (Gradientenabstieg mit Armijo-Schrittweite, konstanter Schrittweite, optimaler Schrittweite und CG) gegenüberstellen.\n",
    "\n",
    "Interpretieren Sie Ihr Ergebnis. Gehen Sie dabei auf die Konvergenzordnung des Gradientenverfahrens mit optimaler Schrittweite bzw. des CG-Verfahrens ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent_quadratic(A,b,x0,tol,itmax):\n",
    "    \n",
    "    ## to be filled in ##\n",
    "    \n",
    "    return x, xvals\n",
    "\n",
    "def mycg(A, b, x0, itmax,tol ):\n",
    "    \n",
    "    ## to be filled in ##\n",
    "    \n",
    "    return x,xvals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vergleich der 4 Verfahren: ## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sei nun $C = \\begin{pmatrix} c & -1 \\\\-1 & c \\end{pmatrix}$ mit $c > 1$ and $d = (0,0)^T$. Lassen Sie die Iterierten des Gradientenverfahrens mit optimaler Schrittweite bzw. des CG-Verfahrens (für die lineare Gleichung $Cx = d$) in einen Höhenlinienplot der Funktion $\\phi(x) = \\frac{1}{2} x^T C x - d^T x$ einzeichnen. Startwert soll für beide Verfahren $x_0 = (c,1)^T$ sein.\n",
    "\n",
    "Variieren Sie $c$ und interpretieren Sie Ihr Ergebnis. Achten Sie dabei darauf, dass der Plot einen sinnvollen Ausschnitt der \"Höhenlandschaft\" von $f$ zeigt, sodass das Verhalten der Iteration erkennbar wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teilaufgabe d: Gauss-Newton Verfahren (6 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie das Gauss-Newton-Verfahren von Übungsblatt 4, Aufgabe 2. Für die Lösung der entsprechenden Least-Squares Probleme können Sie die unten angegebene Funktion $myleastsquares$ verwenden.\n",
    "\n",
    "Input der Funktion $gaussnewton$ soll sein: \n",
    "* Funktion $f$ sowie eine Funktion $df$, die die Jacobi-Matrix von $f$ auswertet   \n",
    "* Vektor $y$ \n",
    "* Starwert $x_0$ und Toleranz $tol$, derart, dass die Iteration abbricht, wenn $\\lVert \\nabla r(x) \\rVert < tol$ erfüllt ist oder eine Maximalzahl $itmax$ von Iterationen erreicht ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myleastsquares(A,b):\n",
    "    Q,R = np.linalg.qr(A)\n",
    "    rhs = (np.transpose(Q)).dot(b)\n",
    "    xmin = np.linalg.solve(R,rhs)\n",
    "    return xmin \n",
    "\n",
    "def gaussnewton(f,df,y,x0,tol,itmax): \n",
    "    \n",
    "    ## to be filled in ##\n",
    "    \n",
    "    return x, xvals\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen Sie Ihre Implementierung anhand des Beispiels aus Aufgabe 2c von Übungsblatt 4. Erstellen Sie einen Plot, aus dem hervorgeht, welche Konvergenzordnung beobachtet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
